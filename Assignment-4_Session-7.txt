Assignment-3_Session-7

Problem Statement:

1. Use the below given dataset

Data Set.

Problem- prediction of the number of the comments in the upcoming 24 hours on those blogs, the train data was 
generated from different base times that may temporally overlap. Therefore, if you simply split the train into
disjoint partitions, the underlying time intervals may overlap. Therefore, you should the provided, temporally
disjoint train and test splits to ensure that the evaluation is fair.

library(dplyr); library(corrplot);library(car); library(MASS); library(ggplot2)
library(reshape2); library(forecast)
# Q1- read the dataset and identify the right features

# import train data set
Variant_1 <- read.csv("E:/Data Analytics with RET/Assignment/Dataset/fbtrain/Features_Variant_1.csv", header=FALSE)
Variant_2 <- read.csv("E:/Data Analytics with RET/Assignment/Dataset/fbtrain/Features_Variant_2.csv", header=FALSE)
Variant_3 <- read.csv("E:/Data Analytics with RET/Assignment/Dataset/fbtrain/Features_Variant_3.csv", header=FALSE)
Variant_4 <- read.csv("E:/Data Analytics with RET/Assignment/Dataset/fbtrain/Features_Variant_4.csv", header=FALSE)
Variant_5 <- read.csv("E:/Data Analytics with RET/Assignment/Dataset/fbtrain/Features_Variant_5.csv", header=FALSE)
fbtrain <- rbind(Variant_1, Variant_2, Variant_3, Variant_4, Variant_5)
dim(fbtrain)

# import test data set
setwd("E:/Data Analytics with RET/Assignment/Dataset/fbtest")
test1 <- read.csv("Test_Case_1.csv", header = F); test2 <- read.csv("Test_Case_2.csv", header = F)
test3 <- read.csv("Test_Case_3.csv", header = F); test4 <- read.csv("Test_Case_4.csv", header = F)
test5 <- read.csv("Test_Case_5.csv", header = F); test6 <- read.csv("Test_Case_6.csv", header = F)
test7 <- read.csv("Test_Case_7.csv", header = F); test8 <- read.csv("Test_Case_8.csv", header = F)
test9 <- read.csv("Test_Case_9.csv", header = F); test10 <- read.csv("Test_Case_10.csv", header = F)
fbtest  <- rbind(test1, test2, test3, test4, test5, test6, test7, test8, test9, test10)
dim(fbtest)

# Assign variable names to the train and test data set
colnames(fbtrain) <- c("plikes","checkin","talking","category","d5","d6","d7","d8","d9","d10","d11","d12",
                    "d13","d14","d15","d16","d17","d18","d19","d20","d21","d22","d23","d24","d25","d26",
                    "d27","d28","d29","cc1","cc2","cc3","cc4","cc5","basetime","postlength","postshre",
                    "postpromo","Hhrs","sun","mon","tue","wed","thu","fri","sat","basesun","basemon",
                    "basetue","basewed","basethu","basefri","basesat","target")
colnames(fbtest) <- c("plikes","checkin","talking","category","d5","d6","d7","d8","d9","d10","d11","d12",
                      "d13","d14","d15","d16","d17","d18","d19","d20","d21","d22","d23","d24","d25","d26",
                      "d27","d28","d29","cc1","cc2","cc3","cc4","cc5","basetime","postlength","postshre",
                      "postpromo","Hhrs","sun","mon","tue","wed","thu","fri","sat","basesun","basemon",
                      "basetue","basewed","basethu","basefri","basesat","target")

dim(fbtrain); dim(fbtest) 
View(fbtrain); View(fbtest)
str(fbtrain); str(fbtest)

train <- fbtrain; test <- fbtest
head(train); head(test)

# making the data tidy by constructing single collumn for post publish day 
train$pubday<- ifelse(train$sun ==1, 1, ifelse(train$mon ==1, 2, ifelse(train$tue ==1, 3,
               ifelse(train$wed ==1, 4, ifelse(train$thu ==1, 5, ifelse(train$fri ==1, 6,
                      ifelse(train$sat ==1, 7, NA)))))))
# making the data tidy by constructing single collumn for base day
train$baseday<- ifelse(train$basesun ==1, 1, ifelse(train$basemon ==1, 2, ifelse(train$basetue ==1, 3,
                        ifelse(train$basewed ==1, 4, ifelse(train$basethu ==1, 5,
                               ifelse(train$basefri ==1, 6, ifelse(train$basesat ==1, 7, NA)))))))
# now the data set is ready

a. Fine tune the model and represent important features
Answer-
final_model <- lm(target ~ talking + d5 + d7 + d8 + d10 + d11 + 
                    d12 + d13 + d16 + d17 + d19 + d20 + d22 + d23 + 
                    cc1 + cc2 + cc3 + cc4 + basetime + postshre + Hhrs, data = train)
summary(final_model)


prediction <- predict(final_model, test)
predicted <- data.frame(cbind(actuals = test$target, prediction = prediction))
predicted$prediction <- ifelse(prediction<0, 0, round(prediction,0))
cor(predicted)
View(predicted)


b. Interpret the summary of the linear model
Answer-
# Residual error is distributed between -346.83 to 1271.33
# P-value of the model is less than alpha (0.05), hence we can accept the model
# 32.46% variability is represented by the model


c. Report the test accuracy vs. the training accuracy
Answer-
# test accuracy
round(accuracy(predicted$prediction,predicted$actuals),3)

prediction <- predict(final_model, test)
predicted <- data.frame(cbind(actuals = test$target, prediction = prediction))
predicted$prediction <- ifelse(prediction<0, 0, round(prediction,0))

min_max_accuracy <- mean(apply(predicted, 1, min) / apply(predicted, 1, max)) 
min_max_accuracy 

# training accuracy
round(accuracy(predicted$prediction,predicted$actuals),3)

prediction <- predict(final_model, train)
predicted <- data.frame(cbind(actuals = train$target, prediction = prediction))
predicted$prediction <- ifelse(prediction<0, 0, round(prediction, 0))
min_max_accuracy <- mean(apply(predicted, 1, min) / apply(predicted, 1, max)) 
min_max_accuracy


d. Interpret the final model coefficients
Answer-
summary(final_model)
coef(final_model) # coefficients of the model
#comments in H Hrs has slope with Independent variables as below:

#  talking            d5            d7            d8           d10           d11 
# -1.858115e-05 -4.759496e-01  8.609203e-01  1.675394e-01 -1.239555e-01 -2.236221e-03 
# d12           d13           d16           d17           d19           d20           d22 
# 1.612318e-01  1.276223e-01  1.114969e-02  1.085186e-01 -1.165972e-01  4.201675e-01 -8.837498e-01 
# d23           cc1           cc2           cc3           cc4      basetime      postshre 
# -2.159461e-01  4.338324e-02  2.196493e-01 -2.272725e-02 -6.728051e-02 -1.933110e-01  2.921963e-03 
# Hhrs 
# 3.880629e-01


e. Plot the model result and compare it with the assumption of the model.
Answer-
par(mfrow=c(2,2))
plot(final_model)

# Model does not pass the test of normality 
# the data is heteroscadatic
# Observations 3528,30608,16432 may have the leverage or potential for influencing the model

